{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682aa4bf",
   "metadata": {},
   "source": [
    "# Lesson 1 - Building a QA Agent with Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44948034",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph LR\n",
    "    %% User / Client Layer\n",
    "    User([User / A2A Client])\n",
    "    \n",
    "    %% Main Orchestrator Layer (Lesson 8)\n",
    "    subgraph OrchestratorLayer [Router/Requirement Agent]\n",
    "        Concierge[\"<b>Healthcare Concierge Agent</b><br/>(BeeAI Framework)<br/><code>Port: 9996</code>\"]\n",
    "    end\n",
    "\n",
    "    subgraph SubAgents [A2A Agent Servers]\n",
    "        direction TB\n",
    "\n",
    "        PolicyAgent[\"<b>Policy Agent</b><br/>(Gemini with A2A SDK)<br/><code>Port: 9999</code>\"]\n",
    "        ResearchAgent[\"<b>Research Agent</b><br/>(Google ADK)<br/><code>Port: 9998</code>\"]\n",
    "\n",
    "        ProviderAgent[\"<b>Provider Agent</b><br/>(LangGraph + LangChain)<br/><code>Port: 9997</code>\"]\n",
    "    end\n",
    "\n",
    "    %% Data & Tools Layer\n",
    "    subgraph DataLayer [Data Sources & Tools]\n",
    "        PDF[\"Policy PDF\"]\n",
    "        Google[Google Search Tool]\n",
    "        MCPServer[\"FastMCP Server<br/>(<code>doctors.json</code>)\"]\n",
    "    end\n",
    "    \n",
    "    Label_UA[\"Sends Query - A2A\"]\n",
    "    Label_CP[\"A2A\"]\n",
    "    Label_CR[\"A2A\"]\n",
    "    Label_CProv[\"A2A\"]\n",
    "    Label_MCP[\"MCP (stdio)\"]\n",
    "\n",
    "    %% -- CONNECTIONS --\n",
    "    \n",
    "    User --- Label_UA --> Concierge\n",
    "\n",
    "    Concierge --- Label_CP --> PolicyAgent\n",
    "    Concierge --- Label_CR --> ResearchAgent\n",
    "    Concierge --- Label_CProv --> ProviderAgent\n",
    "    \n",
    "    PolicyAgent -- \"Reads\" --> PDF\n",
    "    ResearchAgent -- \"Calls\" --> Google\n",
    "    \n",
    "    ProviderAgent --- Label_MCP --> MCPServer\n",
    "\n",
    "    classDef orchestrator fill:#f9f,stroke:#333,stroke-width:2px;\n",
    "    classDef agent fill:#e1f5fe,stroke:#0277bd,stroke-width:2px;\n",
    "    classDef tool fill:#fff3e0,stroke:#ef6c00,stroke-width:1px,stroke-dasharray: 5 5;\n",
    "    \n",
    "    classDef protocolLabel fill:#ffffff,stroke:none,color:#000;\n",
    "    \n",
    "    class Concierge orchestrator;\n",
    "    class PolicyAgent,ResearchAgent,ProviderAgent agent;\n",
    "    class PDF,Google,MCPServer tool;\n",
    "    \n",
    "    class Label_UA,Label_CP,Label_CR,Label_CProv,Label_MCP protocolLabel;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacf96b",
   "metadata": {},
   "source": [
    "In this lesson, you will build a basic Question Answering (QA) agent using [Google Gemini](https://deepmind.google/models/gemini/) via the [Google Gen AI SDK](https://github.com/googleapis/python-genai). You will use **[LiteLLM](https://www.litellm.ai/)** to interact with the model to analyze a PDF document containing health insurance policy details. Then, you will refactor this logic into a reusable Python class, laying the groundwork for the next lesson where you will wrap this agent in an [Agent2Agent (A2A)](https://a2a-protocol.org/) server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860fbdb",
   "metadata": {},
   "source": [
    "## 1.1. Import Libraries and Setup\n",
    "\n",
    "First, import the necessary libraries. You will use `litellm` to interact with the LLM and standard libraries to handle file encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b6e09a-633d-4dd6-a3c8-bdcd6b4e3ee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'a2a.types'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlitellm\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_env\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\loint\\_repos\\a2a\\A2AWalkthrough\\helpers.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnest_asyncio\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01ma2a\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentCard\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msetup_env\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'a2a.types'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import litellm\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from helpers import setup_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3520ec7b-13c1-4efc-b386-6ccecaa0723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "272612c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting a2a\n",
      "  Downloading a2a-0.44.tar.gz (2.0 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting scrapy (from a2a)\n",
      "  Downloading scrapy-2.14.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: tabulate in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from a2a) (0.9.0)\n",
      "Requirement already satisfied: cryptography>=37.0.0 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapy->a2a) (42.0.7)\n",
      "Collecting cssselect>=0.9.1 (from scrapy->a2a)\n",
      "  Downloading cssselect-1.4.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting defusedxml>=0.7.1 (from scrapy->a2a)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting itemadapter>=0.1.0 (from scrapy->a2a)\n",
      "  Downloading itemadapter-0.13.1-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting itemloaders>=1.0.1 (from scrapy->a2a)\n",
      "  Downloading itemloaders-1.4.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: lxml>=4.6.4 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapy->a2a) (4.9.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scrapy->a2a) (24.2)\n",
      "Collecting parsel>=1.5.0 (from scrapy->a2a)\n",
      "  Downloading parsel-1.11.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting protego>=0.1.15 (from scrapy->a2a)\n",
      "  Downloading protego-0.6.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pydispatcher>=2.0.5 (from scrapy->a2a)\n",
      "  Downloading PyDispatcher-2.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyopenssl>=22.0.0 (from scrapy->a2a)\n",
      "  Downloading pyopenssl-25.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting queuelib>=1.4.2 (from scrapy->a2a)\n",
      "  Downloading queuelib-1.9.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting service-identity>=18.1.0 (from scrapy->a2a)\n",
      "  Downloading service_identity-24.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tldextract (from scrapy->a2a)\n",
      "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting twisted<=25.5.0,>=21.7.0 (from scrapy->a2a)\n",
      "  Downloading twisted-25.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting w3lib>=1.17.0 (from scrapy->a2a)\n",
      "  Downloading w3lib-2.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting zope-interface>=5.1.0 (from scrapy->a2a)\n",
      "  Downloading zope_interface-8.2-cp311-cp311-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.7/46.7 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=37.0.0->scrapy->a2a) (1.16.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from itemloaders>=1.0.1->scrapy->a2a) (1.0.1)\n",
      "Collecting lxml>=4.6.4 (from scrapy->a2a)\n",
      "  Downloading lxml-6.0.2-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting cryptography>=37.0.0 (from scrapy->a2a)\n",
      "  Downloading cryptography-46.0.5-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9 in c:\\users\\loint\\appdata\\roaming\\python\\python311\\site-packages (from pyopenssl>=22.0.0->scrapy->a2a) (4.15.0)\n",
      "Collecting cffi>=2.0.0 (from cryptography>=37.0.0->scrapy->a2a)\n",
      "  Using cached cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from service-identity>=18.1.0->scrapy->a2a) (23.2.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from service-identity>=18.1.0->scrapy->a2a) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from service-identity>=18.1.0->scrapy->a2a) (0.4.0)\n",
      "Collecting automat>=24.8.0 (from twisted<=25.5.0,>=21.7.0->scrapy->a2a)\n",
      "  Downloading automat-25.4.16-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting constantly>=15.1 (from twisted<=25.5.0,>=21.7.0->scrapy->a2a)\n",
      "  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting hyperlink>=17.1.1 (from twisted<=25.5.0,>=21.7.0->scrapy->a2a)\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting incremental>=24.7.0 (from twisted<=25.5.0,>=21.7.0->scrapy->a2a)\n",
      "  Downloading incremental-24.11.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tldextract->scrapy->a2a) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tldextract->scrapy->a2a) (2.30.0)\n",
      "Collecting requests-file>=1.4 (from tldextract->scrapy->a2a)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tldextract->scrapy->a2a) (3.24.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=2.0.0->cryptography>=37.0.0->scrapy->a2a) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->a2a) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->a2a) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loint\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy->a2a) (2024.7.4)\n",
      "Downloading scrapy-2.14.1-py3-none-any.whl (331 kB)\n",
      "   ---------------------------------------- 0.0/331.7 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 286.7/331.7 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  327.7/331.7 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  327.7/331.7 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 331.7/331.7 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading cssselect-1.4.0-py3-none-any.whl (18 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading itemadapter-0.13.1-py3-none-any.whl (18 kB)\n",
      "Downloading itemloaders-1.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading parsel-1.11.0-py3-none-any.whl (14 kB)\n",
      "Downloading lxml-6.0.2-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/4.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.8/4.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.1/4.0 MB 8.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.4/4.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.0 MB 8.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.2/4.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.5/4.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.0/4.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.6/4.0 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.6/4.0 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.0 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading protego-0.6.0-py3-none-any.whl (10 kB)\n",
      "Downloading PyDispatcher-2.0.7-py3-none-any.whl (12 kB)\n",
      "Downloading pyopenssl-25.3.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/57.3 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 51.2/57.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.3/57.3 kB 602.9 kB/s eta 0:00:00\n",
      "Downloading cryptography-46.0.5-cp311-abi3-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.7/3.5 MB 22.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.3/3.5 MB 13.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.9/3.5 MB 13.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.9/3.5 MB 13.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading queuelib-1.9.0-py3-none-any.whl (13 kB)\n",
      "Downloading service_identity-24.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading twisted-25.5.0-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.6/3.2 MB 18.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.2/3.2 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.7/3.2 MB 13.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.9/3.2 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.3/3.2 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.8/3.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.2/3.2 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading w3lib-2.4.0-py3-none-any.whl (21 kB)\n",
      "Downloading zope_interface-8.2-cp311-cp311-win_amd64.whl (212 kB)\n",
      "   ---------------------------------------- 0.0/212.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 212.3/212.3 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading tldextract-5.3.1-py3-none-any.whl (105 kB)\n",
      "   ---------------------------------------- 0.0/105.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 105.9/105.9 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading automat-25.4.16-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.8/42.8 kB 2.0 MB/s eta 0:00:00\n",
      "Using cached cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
      "Downloading constantly-23.10.4-py3-none-any.whl (13 kB)\n",
      "Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 74.6/74.6 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading incremental-24.11.0-py3-none-any.whl (21 kB)\n",
      "Downloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Building wheels for collected packages: a2a\n",
      "  Building wheel for a2a (pyproject.toml): started\n",
      "  Building wheel for a2a (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for a2a: filename=a2a-0.44-py3-none-any.whl size=2538 sha256=1dc38661db0756a4771b3774d447fd49ce61bfd91a233e21b53d6b4689396f4a\n",
      "  Stored in directory: c:\\users\\loint\\appdata\\local\\pip\\cache\\wheels\\43\\40\\03\\edb4e47b3102c5b895704e597d81dbec64023897a1943a9f78\n",
      "Successfully built a2a\n",
      "Installing collected packages: pydispatcher, zope-interface, w3lib, queuelib, protego, lxml, itemadapter, incremental, hyperlink, defusedxml, cssselect, constantly, cffi, automat, twisted, requests-file, parsel, cryptography, tldextract, service-identity, pyopenssl, itemloaders, scrapy, a2a\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.3\n",
      "    Uninstalling lxml-4.9.3:\n",
      "      Successfully uninstalled lxml-4.9.3\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.16.0\n",
      "    Uninstalling cffi-1.16.0:\n",
      "      Successfully uninstalled cffi-1.16.0\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 42.0.7\n",
      "    Uninstalling cryptography-42.0.7:\n",
      "      Successfully uninstalled cryptography-42.0.7\n",
      "Successfully installed a2a-0.44 automat-25.4.16 cffi-2.0.0 constantly-23.10.4 cryptography-46.0.5 cssselect-1.4.0 defusedxml-0.7.1 hyperlink-21.0.0 incremental-24.11.0 itemadapter-0.13.1 itemloaders-1.4.0 lxml-6.0.2 parsel-1.11.0 protego-0.6.0 pydispatcher-2.0.7 pyopenssl-25.3.0 queuelib-1.9.0 requests-file-3.0.1 scrapy-2.14.1 service-identity-24.2.0 tldextract-5.3.1 twisted-25.5.0 w3lib-2.4.0 zope-interface-8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script incremental.exe is installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script automat-visualize.exe is installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts cftp.exe, ckeygen.exe, conch.exe, mailmail.exe, pyhtmlizer.exe, tkconch.exe, trial.exe, twist.exe and twistd.exe are installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tldextract.exe is installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script scrapy.exe is installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script a2a.exe is installed in 'c:\\Users\\loint\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sop-deutils 1.0.2.1 requires cryptography==42.0.7, but you have cryptography 46.0.5 which is incompatible.\n",
      "sop-deutils 1.0.2.1 requires lxml==4.9.3, but you have lxml 6.0.2 which is incompatible.\n",
      "sop-deutils 1.0.2.1 requires pandas==2.0.3, but you have pandas 2.2.3 which is incompatible.\n",
      "sop-deutils 1.0.2.1 requires pyarrow==11.0.0, but you have pyarrow 15.0.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install a2a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd488a",
   "metadata": {},
   "source": [
    "## 1.2. Load and Encode Data\n",
    "\n",
    "You read the insurance policy PDF (`2026AnthemgHIPSBC.pdf`) and encode it in base64 so it can be passed to the model as context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dadf2-2825-463d-a7b6-657e54429dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/2026AnthemgHIPSBC.pdf\").open(\"rb\") as file:\n",
    "    pdf_data = base64.standard_b64encode(file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84422142",
   "metadata": {},
   "source": [
    "## 1.3. Query the Model\n",
    "\n",
    "Now you will send a specific query to the model: \"How much would I pay for mental health therapy?\". You provide the model with a system instruction to act as an expert insurance agent and pass the PDF document alongside the user's text prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2682ba-6ea6-4d6c-8955-dedfa892a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How much would I pay for mental health therapy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a15ab1-93b0-4c70-bc4f-743e6a53f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"gemini/gemini-3-flash-preview\",\n",
    "    # For Vertex AI:\n",
    "    # model=\"vertex_ai/gemini-3-flash-preview\",\n",
    "    reasoning_effort=\"minimal\",\n",
    "    max_tokens=1000,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert insurance agent designed to assist with coverage queries. Use the provided documents to answer questions about insurance policies. If the information is not available in the documents, respond with 'I don't know'\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": f\"data:application/pdf;base64,{pdf_data}\"},\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a72ed-3444-46ac-a4b5-600c378b70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.choices[0].message.content.replace(\"$\", r\"\\\\$\")\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c9e25",
   "metadata": {},
   "source": [
    "## 1.4. Refactor into an Agent Class\n",
    "\n",
    "To make this code reusable and easier to integrate into an A2A server later, we have wrapped the logic into a `PolicyAgent` class in a file named `policy_agent.py`. This class initializes the data in the `__init__` method and exposes an `answer_query` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c43d6da-63b3-487e-8677-883e5ec7c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code, display\n",
    "\n",
    "display(Code(\"policy_agent.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d8187",
   "metadata": {},
   "source": [
    "## 1.5. Test the Agent Class\n",
    "\n",
    "Finally, import the `PolicyAgent` class you just created and test it with the same query to ensure it works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d8e65-c99d-44ac-b954-269907a88210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from policy_agent import PolicyAgent\n",
    "\n",
    "print(\"Running Health Insurance Policy Agent\")\n",
    "agent = PolicyAgent()\n",
    "prompt = \"How much would I pay for mental health therapy?\"\n",
    "\n",
    "response = agent.answer_query(prompt)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d2075",
   "metadata": {},
   "source": [
    "## 1.6. Resources\n",
    "\n",
    "- [Google Gemini API Documentation](https://ai.google.dev/docs)\n",
    "- [LiteLLM Documentation](https://docs.litellm.ai/docs/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
